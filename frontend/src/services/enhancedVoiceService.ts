/**
 * üéôÔ∏è Enhanced Voice Service
 * Enterprise-level voice communication —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 1000+ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
 * 
 * –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
 * - WebRTC P2P —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –Ω–∏–∑–∫–æ–π –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å—é
 * - –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∞—É–¥–∏–æ
 * - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
 * - –®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–≤—É–∫–∞
 * - –ë–∞—Ç—á–∏–Ω–≥ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π
 * - –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —ç–∫—Ä–∞–Ω–∞
 * - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
 */

interface VoiceParticipant {
  userId: number;
  username: string;
  displayName?: string;
  avatarUrl?: string;
  isMuted: boolean;
  isDeafened: boolean;
  isSpeaking: boolean;
  audioQuality: 'high' | 'medium' | 'low';
  connectionQuality: number; // 0.0 - 1.0
}

interface VoiceChannelState {
  channelId: number;
  participants: Map<number, VoiceParticipant>;
  iceServers: RTCIceServer[];
  maxParticipants: number;
  bitrate: number;
}

interface AudioConstraints {
  echoCancellation: boolean;
  noiseSuppression: boolean;
  autoGainControl: boolean;
  sampleRate: number;
  channelCount: number;
  bitrate: number;
}

interface VoiceMetrics {
  packetsLost: number;
  packetsReceived: number;
  bytesSent: number;
  bytesReceived: number;
  averageLatency: number;
  jitter: number;
  audioLevel: number;
  connectionState: RTCPeerConnectionState;
}

class EnhancedVoiceService {
  private ws: WebSocket | null = null;
  private peerConnections: Map<number, RTCPeerConnection> = new Map();
  private localStream: MediaStream | null = null;
  private remoteStreams: Map<number, MediaStream> = new Map();
  
  // Voice state
  private currentChannelId: number | null = null;
  private channelState: VoiceChannelState | null = null;
  private isConnected: boolean = false;
  private isMuted: boolean = false;
  private isDeafened: boolean = false;
  private isSpeaking: boolean = false;
  
  // Audio processing
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private gainNode: GainNode | null = null;
  private noiseGate: AudioWorkletNode | null = null;
  
  // Performance monitoring
  private metrics: Map<number, VoiceMetrics> = new Map();
  private performanceInterval: NodeJS.Timeout | null = null;
  
  // Adaptive quality
  private currentAudioConstraints: AudioConstraints = {
    echoCancellation: true,
    noiseSuppression: true,
    autoGainControl: true,
    sampleRate: 48000,
    channelCount: 2,
    bitrate: 64000
  };
  
  // Event handlers
  private eventHandlers: Map<string, ((data: any) => void)[]> = new Map();
  
  // Speaking detection
  private speakingDetectionInterval: NodeJS.Timeout | null = null;
  private lastSpeakingState: boolean = false;
  private speakingThreshold: number = -60; // dB
  
  // Screen sharing
  private screenStream: MediaStream | null = null;
  private isScreenSharing: boolean = false;
  
  constructor() {
    this.initializeAudioContext();
  }

  /**
   * üîä –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AudioContext –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–≤—É–∫–∞
   */
  private async initializeAudioContext() {
    try {
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      
      // Load audio worklet for noise gate
      if (this.audioContext.audioWorklet) {
        try {
          // await this.audioContext.audioWorklet.addModule('/audio-worklets/noise-gate.js');
          // –î–ª—è –¥–µ–º–æ –≤–µ—Ä—Å–∏–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º worklet
        } catch (error) {
          console.warn('[Voice] Audio worklet not available:', error);
        }
      }
      
    } catch (error) {
      console.error('[Voice] Failed to initialize AudioContext:', error);
    }
  }

  /**
   * üîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –≥–æ–ª–æ—Å–æ–≤–æ–º—É –∫–∞–Ω–∞–ª—É
   */
  async connectToVoiceChannel(channelId: number, token: string): Promise<boolean> {
    if (this.isConnected && this.currentChannelId === channelId) {
      return true;
    }

    try {
      // –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–Ω–∞–ª–∞
      if (this.isConnected) {
        await this.disconnect();
      }

      // –£—Å—Ç–∞–Ω–æ–≤–∫–∞ WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
      const wsUrl = `${process.env.NEXT_PUBLIC_WS_URL || 'wss://miscord.ru'}/ws/voice/${channelId}?token=${token}`;
      this.ws = new WebSocket(wsUrl);

      return new Promise((resolve, reject) => {
        if (!this.ws) {
          reject(new Error('WebSocket not initialized'));
          return;
        }

        this.ws.onopen = async () => {
          this.currentChannelId = channelId;
          this.isConnected = true;
          
          // –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ–¥–∏–∞ —Å—Ç—Ä–∏–º–∞
          await this.initializeMediaStream();
          
          // –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
          this.startPerformanceMonitoring();
          this.startSpeakingDetection();
          
          this.emit('connected', { channelId });
          resolve(true);
        };

        this.ws.onmessage = (event) => {
          this.handleWebSocketMessage(event);
        };

        this.ws.onclose = () => {
          this.handleDisconnection();
          resolve(false);
        };

        this.ws.onerror = (error) => {
          console.error('[Voice] WebSocket error:', error);
          reject(error);
        };

        // Connection timeout
        setTimeout(() => {
          if (!this.isConnected) {
            this.ws?.close();
            reject(new Error('Connection timeout'));
          }
        }, 10000);
      });

    } catch (error) {
      console.error('[Voice] Connection error:', error);
      return false;
    }
  }

  /**
   * üé§ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–¥–∏–∞ —Å—Ç—Ä–∏–º–∞
   */
  private async initializeMediaStream(): Promise<void> {
    try {
      // –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∞—É–¥–∏–æ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —Å–µ—Ç–∏
      const constraints: MediaStreamConstraints = {
        audio: {
          echoCancellation: this.currentAudioConstraints.echoCancellation,
          noiseSuppression: this.currentAudioConstraints.noiseSuppression,
          autoGainControl: this.currentAudioConstraints.autoGainControl,
          sampleRate: this.currentAudioConstraints.sampleRate,
          channelCount: this.currentAudioConstraints.channelCount,
        }
      };

      this.localStream = await navigator.mediaDevices.getUserMedia(constraints);
      
      // –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏
      await this.applyAudioProcessing();
      
      this.emit('localStreamReady', { stream: this.localStream });
      
    } catch (error) {
      console.error('[Voice] Failed to get user media:', error);
      throw error;
    }
  }

  /**
   * üéõÔ∏è –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏
   */
  private async applyAudioProcessing(): Promise<void> {
    if (!this.localStream || !this.audioContext) return;

    try {
      const source = this.audioContext.createMediaStreamSource(this.localStream);
      
      // –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ä–µ—á–∏
      this.analyser = this.audioContext.createAnalyser();
      this.analyser.fftSize = 1024;
      this.analyser.smoothingTimeConstant = 0.3;
      
      // Gain node –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç—å—é
      this.gainNode = this.audioContext.createGain();
      this.gainNode.gain.value = this.isMuted ? 0 : 1;
      
      // –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É–∑–ª–æ–≤
      source.connect(this.analyser);
      this.analyser.connect(this.gainNode);
      
      // –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Å—Ç—Ä–∏–º–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –∞—É–¥–∏–æ
      const destination = this.audioContext.createMediaStreamDestination();
      this.gainNode.connect(destination);
      
      // –ó–∞–º–µ–Ω–∞ —Ç—Ä–µ–∫–æ–≤ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º —Å—Ç—Ä–∏–º–µ
      const processedTrack = destination.stream.getAudioTracks()[0];
      const originalTrack = this.localStream.getAudioTracks()[0];
      
      if (originalTrack && processedTrack) {
        this.localStream.removeTrack(originalTrack);
        this.localStream.addTrack(processedTrack);
        originalTrack.stop();
      }
      
    } catch (error) {
      console.error('[Voice] Audio processing setup failed:', error);
    }
  }

  /**
   * üì® –û–±—Ä–∞–±–æ—Ç–∫–∞ WebSocket —Å–æ–æ–±—â–µ–Ω–∏–π
   */
  private handleWebSocketMessage(event: MessageEvent): void {
    try {
      const data = JSON.parse(event.data);
      
      switch (data.type) {
        case 'participants':
          this.handleParticipantsUpdate(data);
          break;
        case 'user_joined_voice':
          this.handleUserJoined(data);
          break;
        case 'user_left_voice':
          this.handleUserLeft(data);
          break;
        case 'offer':
          this.handleWebRTCOffer(data);
          break;
        case 'answer':
          this.handleWebRTCAnswer(data);
          break;
        case 'ice_candidate':
          this.handleICECandidate(data);
          break;
        case 'batch_speaking':
          this.handleBatchSpeaking(data);
          break;
        case 'batch_status':
          this.handleBatchStatus(data);
          break;
        case 'screen_share_started':
          this.handleScreenShareStarted(data);
          break;
        case 'screen_share_stopped':
          this.handleScreenShareStopped(data);
          break;
      }
      
    } catch (error) {
      console.error('[Voice] Message parsing error:', error);
    }
  }

  /**
   * üë• –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
   */
  private handleParticipantsUpdate(data: any): void {
    if (!data.participants) return;

    const participants = new Map<number, VoiceParticipant>();
    
    for (const p of data.participants) {
      participants.set(p.user_id, {
        userId: p.user_id,
        username: p.username,
        displayName: p.display_name,
        avatarUrl: p.avatar_url,
        isMuted: p.is_muted,
        isDeafened: p.is_deafened,
        isSpeaking: p.is_speaking,
        audioQuality: p.audio_quality || 'high',
        connectionQuality: p.connection_quality || 1.0
      });
    }

    this.channelState = {
      channelId: this.currentChannelId!,
      participants,
      iceServers: data.ice_servers || [],
      maxParticipants: data.channel_settings?.max_participants || 50,
      bitrate: data.channel_settings?.bitrate || 64000
    };

    // –°–æ–∑–¥–∞–Ω–∏–µ P2P —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å –Ω–æ–≤—ã–º–∏ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏
    for (const userId of Array.from(participants.keys())) {
      if (userId !== this.getCurrentUserId() && !this.peerConnections.has(userId)) {
        this.createPeerConnection(userId, true);
      }
    }

    this.emit('participantsUpdated', { participants: Array.from(participants.values()) });
  }

  /**
   * ü§ù –°–æ–∑–¥–∞–Ω–∏–µ P2P —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
   */
  private async createPeerConnection(userId: number, shouldCreateOffer: boolean): Promise<void> {
    if (!this.channelState) return;

    try {
      const pc = new RTCPeerConnection({
        iceServers: this.channelState.iceServers,
        iceCandidatePoolSize: 10
      });

      // –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å—Ç—Ä–∏–º–∞
      if (this.localStream) {
        for (const track of this.localStream.getTracks()) {
          pc.addTrack(track, this.localStream);
        }
      }

      // –û–±—Ä–∞–±–æ—Ç–∫–∞ ICE –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
      pc.onicecandidate = (event) => {
        if (event.candidate) {
          this.sendWebRTCMessage({
            type: 'ice_candidate',
            target_id: userId,
            candidate: event.candidate.candidate,
            sdpMid: event.candidate.sdpMid,
            sdpMLineIndex: event.candidate.sdpMLineIndex
          });
        }
      };

      // –û–±—Ä–∞–±–æ—Ç–∫–∞ —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ —Å—Ç—Ä–∏–º–∞
      pc.ontrack = (event) => {
        const [remoteStream] = event.streams;
        this.remoteStreams.set(userId, remoteStream);
        this.emit('remoteStreamAdded', { userId, stream: remoteStream });
      };

      // –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
      pc.onconnectionstatechange = () => {
        this.updateConnectionMetrics(userId, pc);
        
        if (pc.connectionState === 'failed' || pc.connectionState === 'closed') {
          this.handlePeerConnectionFailure(userId);
        }
      };

      this.peerConnections.set(userId, pc);

      // –°–æ–∑–¥–∞–Ω–∏–µ offer –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
      if (shouldCreateOffer) {
        const offer = await pc.createOffer({
          offerToReceiveAudio: true,
          offerToReceiveVideo: false
        });
        
        await pc.setLocalDescription(offer);
        
        this.sendWebRTCMessage({
          type: 'offer',
          target_id: userId,
          sdp: offer.sdp
        });
      }

    } catch (error) {
      console.error(`[Voice] Failed to create peer connection with ${userId}:`, error);
    }
  }

  /**
   * üìû –û–±—Ä–∞–±–æ—Ç–∫–∞ WebRTC offer
   */
  private async handleWebRTCOffer(data: any): Promise<void> {
    const { from_id: fromId, sdp } = data;
    
    if (!this.peerConnections.has(fromId)) {
      await this.createPeerConnection(fromId, false);
    }

    const pc = this.peerConnections.get(fromId);
    if (!pc) return;

    try {
      await pc.setRemoteDescription(new RTCSessionDescription({ type: 'offer', sdp }));
      
      const answer = await pc.createAnswer();
      await pc.setLocalDescription(answer);
      
      this.sendWebRTCMessage({
        type: 'answer',
        target_id: fromId,
        sdp: answer.sdp
      });

    } catch (error) {
      console.error(`[Voice] Failed to handle offer from ${fromId}:`, error);
    }
  }

  /**
   * üìû –û–±—Ä–∞–±–æ—Ç–∫–∞ WebRTC answer
   */
  private async handleWebRTCAnswer(data: any): Promise<void> {
    const { from_id: fromId, sdp } = data;
    const pc = this.peerConnections.get(fromId);
    
    if (!pc) return;

    try {
      await pc.setRemoteDescription(new RTCSessionDescription({ type: 'answer', sdp }));
    } catch (error) {
      console.error(`[Voice] Failed to handle answer from ${fromId}:`, error);
    }
  }

  /**
   * üßä –û–±—Ä–∞–±–æ—Ç–∫–∞ ICE candidate
   */
  private async handleICECandidate(data: any): Promise<void> {
    const { from_id: fromId, candidate, sdpMid, sdpMLineIndex } = data;
    const pc = this.peerConnections.get(fromId);
    
    if (!pc) return;

    try {
      await pc.addIceCandidate(new RTCIceCandidate({
        candidate,
        sdpMid,
        sdpMLineIndex
      }));
    } catch (error) {
      console.error(`[Voice] Failed to add ICE candidate from ${fromId}:`, error);
    }
  }

  /**
   * üó£Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —Å–æ–±—ã—Ç–∏–π —Ä–µ—á–∏
   */
  private handleBatchSpeaking(data: any): void {
    if (!data.events) return;

    for (const [userIdStr, isSpeaking] of Object.entries(data.events)) {
      const userId = parseInt(userIdStr);
      this.updateParticipantSpeaking(userId, isSpeaking as boolean);
    }
  }

  /**
   * üéõÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —Å—Ç–∞—Ç—É—Å–æ–≤
   */
  private handleBatchStatus(data: any): void {
    if (!data.events) return;

    for (const [userIdStr, status] of Object.entries(data.events)) {
      const userId = parseInt(userIdStr);
      this.updateParticipantStatus(userId, status as any);
    }
  }

  /**
   * üó£Ô∏è –î–µ—Ç–µ–∫—Ü–∏—è —Ä–µ—á–∏
   */
  private startSpeakingDetection(): void {
    if (!this.analyser) return;

    this.speakingDetectionInterval = setInterval(() => {
      if (!this.analyser || this.isMuted) return;

      const dataArray = new Uint8Array(this.analyser.frequencyBinCount);
      this.analyser.getByteFrequencyData(dataArray);

      // –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è –∞—É–¥–∏–æ
      const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
      const decibels = 20 * Math.log10(average / 255);

      const currentlySpeaking = decibels > this.speakingThreshold;

      if (currentlySpeaking !== this.lastSpeakingState) {
        this.lastSpeakingState = currentlySpeaking;
        this.isSpeaking = currentlySpeaking;
        
        this.sendWebSocketMessage({
          type: 'speaking',
          is_speaking: currentlySpeaking
        });

        this.emit('speakingChanged', { isSpeaking: currentlySpeaking });
      }

    }, 100); // –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 100ms
  }

  /**
   * üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
   */
  private startPerformanceMonitoring(): void {
    this.performanceInterval = setInterval(async () => {
      for (const [userId, pc] of this.peerConnections) {
        await this.updateConnectionMetrics(userId, pc);
      }
      
      // –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
      this.adaptAudioQuality();
      
    }, 5000); // –ö–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
  }

  /**
   * üìà –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
   */
  private async updateConnectionMetrics(userId: number, pc: RTCPeerConnection): Promise<void> {
    try {
      const stats = await pc.getStats();
      let metrics: Partial<VoiceMetrics> = {
        connectionState: pc.connectionState
      };

      stats.forEach((report) => {
        if (report.type === 'inbound-rtp' && report.mediaType === 'audio') {
          metrics.packetsReceived = report.packetsReceived || 0;
          metrics.packetsLost = report.packetsLost || 0;
          metrics.bytesReceived = report.bytesReceived || 0;
          metrics.jitter = report.jitter || 0;
        }
        
        if (report.type === 'outbound-rtp' && report.mediaType === 'audio') {
          metrics.bytesSent = report.bytesSent || 0;
        }
      });

      this.metrics.set(userId, { ...this.metrics.get(userId), ...metrics } as VoiceMetrics);
      
    } catch (error) {
      console.error(`[Voice] Failed to get stats for ${userId}:`, error);
    }
  }

  /**
   * üîß –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ
   */
  private adaptAudioQuality(): void {
    const totalParticipants = this.peerConnections.size;
    
    // –°–Ω–∏–∂–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏ –±–æ–ª—å—à–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
    if (totalParticipants > 20) {
      this.currentAudioConstraints.bitrate = 32000; // 32 kbps
      this.currentAudioConstraints.sampleRate = 24000;
    } else if (totalParticipants > 10) {
      this.currentAudioConstraints.bitrate = 48000; // 48 kbps
      this.currentAudioConstraints.sampleRate = 32000;
    } else {
      this.currentAudioConstraints.bitrate = 64000; // 64 kbps
      this.currentAudioConstraints.sampleRate = 48000;
    }
  }

  // Public API methods

  /**
   * üîá –í–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–∫–ª—é—á–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
   */
  async toggleMute(): Promise<void> {
    this.isMuted = !this.isMuted;
    
    if (this.gainNode) {
      this.gainNode.gain.value = this.isMuted ? 0 : 1;
    }
    
    if (this.localStream) {
      this.localStream.getAudioTracks().forEach(track => {
        track.enabled = !this.isMuted;
      });
    }

    this.sendWebSocketMessage({
      type: 'mute',
      is_muted: this.isMuted
    });

    this.emit('muteChanged', { isMuted: this.isMuted });
  }

  /**
   * üîá –í–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞—É—à–Ω–∏–∫–æ–≤
   */
  async toggleDeafen(): Promise<void> {
    this.isDeafened = !this.isDeafened;
    
    // –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –≤—Å–µ—Ö —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∏–º–æ–≤
    for (const [userId, stream] of this.remoteStreams) {
      stream.getAudioTracks().forEach(track => {
        track.enabled = !this.isDeafened;
      });
    }

    this.sendWebSocketMessage({
      type: 'deafen',
      is_deafened: this.isDeafened
    });

    this.emit('deafenChanged', { isDeafened: this.isDeafened });
  }

  /**
   * üñ•Ô∏è –ù–∞—á–∞–ª–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —ç–∫—Ä–∞–Ω–∞
   */
  async startScreenShare(): Promise<boolean> {
    if (this.isScreenSharing) return true;

    try {
      this.screenStream = await navigator.mediaDevices.getDisplayMedia({
        video: true,
        audio: true
      });

      // –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∏–¥–µ–æ —Ç—Ä–µ–∫–∞ –≤–æ –≤—Å–µ peer connections
      const videoTrack = this.screenStream.getVideoTracks()[0];
      if (videoTrack) {
        for (const pc of this.peerConnections.values()) {
          const sender = pc.getSenders().find(s => s.track?.kind === 'video');
          if (sender) {
            await sender.replaceTrack(videoTrack);
          } else {
            pc.addTrack(videoTrack, this.screenStream);
          }
        }
      }

      // –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —ç–∫—Ä–∞–Ω–∞
      videoTrack.onended = () => {
        this.stopScreenShare();
      };

      this.isScreenSharing = true;
      
      this.sendWebSocketMessage({
        type: 'screen_share_start'
      });

      this.emit('screenShareStarted', { stream: this.screenStream });
      return true;

    } catch (error) {
      console.error('[Voice] Failed to start screen share:', error);
      return false;
    }
  }

  /**
   * üñ•Ô∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —ç–∫—Ä–∞–Ω–∞
   */
  async stopScreenShare(): Promise<void> {
    if (!this.isScreenSharing || !this.screenStream) return;

    // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö —Ç—Ä–µ–∫–æ–≤
    this.screenStream.getTracks().forEach(track => track.stop());
    
    // –£–¥–∞–ª–µ–Ω–∏–µ –≤–∏–¥–µ–æ —Ç—Ä–µ–∫–∞ –∏–∑ peer connections
    for (const pc of this.peerConnections.values()) {
      const videoSender = pc.getSenders().find(s => s.track?.kind === 'video');
      if (videoSender) {
        pc.removeTrack(videoSender);
      }
    }

    this.screenStream = null;
    this.isScreenSharing = false;

    this.sendWebSocketMessage({
      type: 'screen_share_stop'
    });

    this.emit('screenShareStopped', {});
  }

  /**
   * üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ WebSocket —Å–æ–æ–±—â–µ–Ω–∏—è
   */
  private sendWebSocketMessage(data: any): void {
    if (this.ws && this.ws.readyState === WebSocket.OPEN) {
      this.ws.send(JSON.stringify(data));
    }
  }

  /**
   * üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ WebRTC —Å–æ–æ–±—â–µ–Ω–∏—è
   */
  private sendWebRTCMessage(data: any): void {
    this.sendWebSocketMessage(data);
  }

  /**
   * üëÇ –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ —Å–æ–±—ã—Ç–∏—è
   */
  on(event: string, handler: (data: any) => void): () => void {
    if (!this.eventHandlers.has(event)) {
      this.eventHandlers.set(event, []);
    }
    
    this.eventHandlers.get(event)!.push(handler);
    
    return () => {
      const handlers = this.eventHandlers.get(event);
      if (handlers) {
        const index = handlers.indexOf(handler);
        if (index > -1) {
          handlers.splice(index, 1);
        }
      }
    };
  }

  /**
   * üì° –≠–º–∏—Å—Å–∏—è —Å–æ–±—ã—Ç–∏—è
   */
  private emit(event: string, data: any): void {
    const handlers = this.eventHandlers.get(event) || [];
    handlers.forEach(handler => {
      try {
        handler(data);
      } catch (error) {
        console.error(`[Voice] Event handler error for ${event}:`, error);
      }
    });
  }

  // Utility methods

  private updateParticipantSpeaking(userId: number, isSpeaking: boolean): void {
    if (this.channelState?.participants.has(userId)) {
      const participant = this.channelState.participants.get(userId)!;
      participant.isSpeaking = isSpeaking;
      this.emit('participantSpeakingChanged', { userId, isSpeaking });
    }
  }

  private updateParticipantStatus(userId: number, status: any): void {
    if (this.channelState?.participants.has(userId)) {
      const participant = this.channelState.participants.get(userId)!;
      Object.assign(participant, status);
      this.emit('participantStatusChanged', { userId, status });
    }
  }

  private handleUserJoined(data: any): void {
    if (this.channelState) {
      const participant: VoiceParticipant = {
        userId: data.user_id,
        username: data.username,
        displayName: data.display_name,
        avatarUrl: data.avatar_url,
        isMuted: false,
        isDeafened: false,
        isSpeaking: false,
        audioQuality: 'high',
        connectionQuality: 1.0
      };
      
      this.channelState.participants.set(data.user_id, participant);
      this.createPeerConnection(data.user_id, true);
      this.emit('userJoined', { participant });
    }
  }

  private handleUserLeft(data: any): void {
    const userId = data.user_id;
    
    // –£–¥–∞–ª–µ–Ω–∏–µ peer connection
    const pc = this.peerConnections.get(userId);
    if (pc) {
      pc.close();
      this.peerConnections.delete(userId);
    }
    
    // –£–¥–∞–ª–µ–Ω–∏–µ remote stream
    this.remoteStreams.delete(userId);
    
    // –£–¥–∞–ª–µ–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–∞
    this.channelState?.participants.delete(userId);
    
    this.emit('userLeft', { userId });
  }

  private handlePeerConnectionFailure(userId: number): void {
    // –ü–æ–ø—ã—Ç–∫–∞ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    setTimeout(() => {
      if (this.channelState?.participants.has(userId)) {
        this.createPeerConnection(userId, true);
      }
    }, 2000);
  }

  private handleDisconnection(): void {
    this.isConnected = false;
    this.currentChannelId = null;
    
    // –ó–∞–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö peer connections
    for (const pc of this.peerConnections.values()) {
      pc.close();
    }
    this.peerConnections.clear();
    
    // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    if (this.performanceInterval) {
      clearInterval(this.performanceInterval);
      this.performanceInterval = null;
    }
    
    if (this.speakingDetectionInterval) {
      clearInterval(this.speakingDetectionInterval);
      this.speakingDetectionInterval = null;
    }
    
    this.emit('disconnected', {});
  }

  private handleScreenShareStarted(data: any): void {
    this.emit('participantScreenShareStarted', { userId: data.user_id });
  }

  private handleScreenShareStopped(data: any): void {
    this.emit('participantScreenShareStopped', { userId: data.user_id });
  }

  private getCurrentUserId(): number {
    // –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è ID —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    // –î–ª—è –¥–µ–º–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
    return 0;
  }

  /**
   * üìä –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
   */
  getMetrics(): Map<number, VoiceMetrics> {
    return new Map(this.metrics);
  }

  /**
   * üìä –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–∞–Ω–∞–ª–µ
   */
  getChannelState(): VoiceChannelState | null {
    return this.channelState;
  }

  /**
   * ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
   */
  getConnectionState(): boolean {
    return this.isConnected;
  }

  /**
   * üõë –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∫–∞–Ω–∞–ª–∞
   */
  async disconnect(): Promise<void> {
    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }
    
    // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å—Ç—Ä–∏–º–∞
    if (this.localStream) {
      this.localStream.getTracks().forEach(track => track.stop());
      this.localStream = null;
    }
    
    // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —ç–∫—Ä–∞–Ω–∞
    if (this.isScreenSharing) {
      await this.stopScreenShare();
    }
    
    this.handleDisconnection();
  }
}

// Create singleton instance
const enhancedVoiceService = new EnhancedVoiceService();

export default enhancedVoiceService; 